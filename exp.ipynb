{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_extractor_v2 import MultiFileFunctionExtractor\n",
    "from prompt_generator import PromptGenerator\n",
    "from call_llm import call_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function details saved to ./function_details_v2.json\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"/home/adityadev/GPTDecoder/model.py\"  # Replace with the path to your Python file\n",
    "# file_paths = [\"/Users/jaylodha/Desktop/GPTDecoder/model.py\", \"/Users/jaylodha/Desktop/GPTDecoder/data_loader.py\"]  # List of Python files to process\n",
    "file_paths = [\"/Users/jaylodha/Desktop/chillmate/app/backend/chatbot/generate_goals.py\"]\n",
    "output_file = \"./function_details_v2.json\"  # Output JSON file name\n",
    "\n",
    "extractor = MultiFileFunctionExtractor(file_paths, output_file)\n",
    "extractor.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart Software Developer who handles large-scale Machine Learning Projects. Your task is to help the user by writing or improving code based on their input. You have access to all relevant class and method details.\n",
      "\n",
      "The user requested the following:\n",
      "\n",
      "I need your help in writing a function for a flask based endpoint based on below requirements:\n",
      "\n",
      "  1. Extract `input_text` from `request.json`, where the input key can be accessed using the key `\"input_text\"`.\n",
      "  2. If the extracted input string is empty, return an empty JSON response with a 400 status code.\n",
      "  3. If the input string is valid, define the following variables:\n",
      "     - `model_name`: Set to `\"llama3-8b-8192\"`.\n",
      "     - `provider_name`: Set to `\"groq\"`.\n",
      "  4. Define an extraction JSON object named `ext_json`. Format for the same is present under Relevant Method Details section. Please keep it strictly consistent.\n",
      "  5. Prepare a context dictionary (`context`).\n",
      "  6. Use the \"generate\" method of the \"GenerateGoal\" class to process the context and generate the required subtasks. Refer to the class and method parameters to integrate it correctly.\n",
      "  7. Return the result from the \"generate\" method by converting it into a JSON response with a 200 status code.\n",
      "\n",
      "  Additional Details:\n",
      "  - The endpoint should be part of the `\"chatbot_bp\"` Flask blueprint.\n",
      "  - Include proper import statements for Flask modules like `request` and `jsonify`, as well as the `GenerateGoal` class.\n",
      "  - Ensure proper error handling for cases like empty input or unexpected errors during processing.\n",
      "  - Log the `input_text`, the parsed output, and any errors using `logger.debug` and `logger.error`.\n",
      "\n",
      "Relevant Method Details:\n",
      "**GenerateGoal.__init__**:\n",
      "Initializes the GenerateGoal class.\n",
      "\n",
      "Args:\n",
      "    model_name (str): The name of the language model to be used.\n",
      "    provider_name (str): The name of the provider for the language model.\n",
      "**GenerateGoal.generate**:\n",
      "Generates goals based on the provided context using prompts and the language model.\n",
      "\n",
      "Args:\n",
      "    context (dict): A dictionary containing context values- user_query and ext_json\n",
      "\n",
      "    ext_json format:\n",
      "    ```\n",
      "    {\n",
      "        'goal': '[Original goal/problem]',\n",
      "        'subtasks': [\n",
      "            {\n",
      "                'subtask': '[Description of subtask 1]',\n",
      "                'importance': '[Explanation of why this subtask is necessary]',\n",
      "                'focus': '[What the student should concentrate on for this subtask]'\n",
      "            },\n",
      "        ]\n",
      "    }\n",
      "    ```\n",
      "\n",
      "Returns:\n",
      "    dict: The parsed output from the language model in dictionary format.\n"
     ]
    }
   ],
   "source": [
    "# Path to the centralized JSON file\n",
    "json_file = \"./function_details_v2.json\"\n",
    "\n",
    "# Example user input\n",
    "user_prompt = \"\"\"I need your help in writing a function for a flask based endpoint based on below requirements:\n",
    "\n",
    "  1. Extract `input_text` from `request.json`, where the input key can be accessed using the key `\"input_text\"`.\n",
    "  2. If the extracted input string is empty, return an empty JSON response with a 400 status code.\n",
    "  3. If the input string is valid, define the following variables:\n",
    "     - `model_name`: Set to `\"llama3-8b-8192\"`.\n",
    "     - `provider_name`: Set to `\"groq\"`.\n",
    "  4. Define an extraction JSON object named `ext_json`. Format for the same is present under Relevant Method Details section. Please keep it strictly consistent.\n",
    "  5. Prepare a context dictionary (`context`).\n",
    "  6. Use the \"generate\" method of the \"GenerateGoal\" class to process the context and generate the required subtasks. Refer to the class and method parameters to integrate it correctly.\n",
    "  7. Return the result from the \"generate\" method by converting it into a JSON response with a 200 status code.\n",
    "\n",
    "  Additional Details:\n",
    "  - The endpoint should be part of the `\"chatbot_bp\"` Flask blueprint.\n",
    "  - Include proper import statements for Flask modules like `request` and `jsonify`, as well as the `GenerateGoal` class.\n",
    "  - Ensure proper error handling for cases like empty input or unexpected errors during processing.\n",
    "  - Log the `input_text`, the parsed output, and any errors using `logger.debug` and `logger.error`.\"\"\"\n",
    "\n",
    "# Initialize the prompt generator\n",
    "prompt_generator = PromptGenerator(json_file)\n",
    "\n",
    "# Generate the final prompt\n",
    "final_prompt = prompt_generator.generate_prompt(user_prompt)\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 14:32:24.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcall_llm\u001b[0m:\u001b[36mcall_llm\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel being used: llama-3.3-70b-versatile\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "out, time_taken = call_llm(system_msg=final_prompt, model_name=model_name, seed= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{   \"code\": \"\\\\n      from flask import Blueprint, request, jsonify\\\\n      from your_module import GenerateGoal\\\\n      import logging\\\\n\\\\n      chatbot_bp = Blueprint(\\'chatbot_bp\\', __name__)\\\\n      logger = logging.getLogger(__name__)\\\\n\\\\n      @chatbot_bp.route(\\'/generate_subtasks\\', methods=[\\'POST\\'])\\\\n      def generate_subtasks():\\\\n          try:\\\\n              input_text = request.json.get(\\'input_text\\')\\\\n              if not input_text:\\\\n                  return jsonify({}), 400\\\\n\\\\n              model_name = \\'llama3-8b-8192\\'\\\\n              provider_name = \\'groq\\'\\\\n\\\\n              ext_json = {\\\\n                  \\'goal\\': input_text,\\\\n                  \\'subtasks\\': []\\\\n              }\\\\n\\\\n              context = {\\\\n                  \\'user_query\\': input_text,\\\\n                  \\'ext_json\\': ext_json\\\\n              }\\\\n\\\\n              generate_goal = GenerateGoal(model_name, provider_name)\\\\n              result = generate_goal.generate(context)\\\\n\\\\n              logger.debug(f\\'Input Text: {input_text}\\')\\\\n              logger.debug(f\\'Parsed Output: {result}\\')\\\\n\\\\n              return jsonify(result), 200\\\\n          except Exception as e:\\\\n              logger.error(f\\'Error: {str(e)}\\')\\\\n              return jsonify({}), 500\\\\n   \"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_json = json.loads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['code'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      from flask import Blueprint, request, jsonify\n",
      "      from your_module import GenerateGoal\n",
      "      import logging\n",
      "\n",
      "      chatbot_bp = Blueprint('chatbot_bp', __name__)\n",
      "      logger = logging.getLogger(__name__)\n",
      "\n",
      "      @chatbot_bp.route('/generate_subtasks', methods=['POST'])\n",
      "      def generate_subtasks():\n",
      "          try:\n",
      "              input_text = request.json.get('input_text')\n",
      "              if not input_text:\n",
      "                  return jsonify({}), 400\n",
      "\n",
      "              model_name = 'llama3-8b-8192'\n",
      "              provider_name = 'groq'\n",
      "\n",
      "              ext_json = {\n",
      "                  'goal': input_text,\n",
      "                  'subtasks': []\n",
      "              }\n",
      "\n",
      "              context = {\n",
      "                  'user_query': input_text,\n",
      "                  'ext_json': ext_json\n",
      "              }\n",
      "\n",
      "              generate_goal = GenerateGoal(model_name, provider_name)\n",
      "              result = generate_goal.generate(context)\n",
      "\n",
      "              logger.debug(f'Input Text: {input_text}')\n",
      "              logger.debug(f'Parsed Output: {result}')\n",
      "\n",
      "              return jsonify(result), 200\n",
      "          except Exception as e:\n",
      "              logger.error(f'Error: {str(e)}')\n",
      "              return jsonify({}), 500\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "print(out_json['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chillmate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
